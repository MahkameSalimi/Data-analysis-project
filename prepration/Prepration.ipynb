{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T19:20:11.059002Z",
     "start_time": "2024-12-17T19:20:10.425476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from seaborn import xkcd_palette\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import numpy as np"
   ],
   "id": "9ec7a658d3634e25",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T19:20:21.537027Z",
     "start_time": "2024-12-17T19:20:21.472619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('mimic_flood_drivers_dataset.csv')\n",
    "\n",
    "# Identify label columns (assuming they are named L1, L2, ..., Ln)\n",
    "label_columns = [col for col in data.columns if col.startswith('L')]\n",
    "\n",
    "# Define categories based on column prefixes\n",
    "categories = {\n",
    "    \"Labels\": label_columns,\n",
    "    \"Topography\": [col for col in data.columns if col.startswith(\"T\")],\n",
    "    \"Hydrological\": [col for col in data.columns if col.startswith(\"H\")],\n",
    "    \"Vegetation\": [col for col in data.columns if col.startswith(\"V\")],\n",
    "    \"Shape\": [col for col in data.columns if col.startswith(\"S\")],\n",
    "    \"Climate\": [col for col in data.columns if col.startswith(\"C\")]\n",
    "}\n",
    "\n",
    "# Create separate dataframes for each category\n",
    "category_dataframes = {category: data[columns] for category, columns in categories.items()}\n",
    "\n",
    "# Print each category and its columns\n",
    "print(\"Categories and their columns:\")\n",
    "for category, columns in categories.items():\n",
    "    print(f\"\\nCategory: {category}\")\n",
    "    print(f\"Columns: {columns}\")\n",
    "\n",
    "# Preview one of the category-specific dataframes (e.g., Topography)\n",
    "print(\"\\nPreview of Topography DataFrame:\")\n",
    "print(category_dataframes[\"Topography\"].head())\n",
    "data.head()"
   ],
   "id": "598a710308236194",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories and their columns:\n",
      "\n",
      "Category: Labels\n",
      "Columns: ['L1', 'L2', 'L3', 'L4', 'L5', 'L6', 'L7', 'L8', 'L9', 'L10', 'L11', 'L12']\n",
      "\n",
      "Category: Topography\n",
      "Columns: ['T1', 'T2', 'T3', 'T6', 'T4', 'T7', 'T8', 'T9', 'T10', 'T11', 'T5']\n",
      "\n",
      "Category: Hydrological\n",
      "Columns: ['H1', 'H6', 'H7', 'H8', 'H2', 'H3', 'H4', 'H5', 'H9', 'H10', 'H11', 'H12']\n",
      "\n",
      "Category: Vegetation\n",
      "Columns: ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8']\n",
      "\n",
      "Category: Shape\n",
      "Columns: ['S11', 'S8', 'S9', 'S10', 'S2', 'S1', 'S3', 'S4', 'S5', 'S7', 'S6']\n",
      "\n",
      "Category: Climate\n",
      "Columns: ['C1', 'C2']\n",
      "\n",
      "Preview of Topography DataFrame:\n",
      "           T1          T2           T3         T6         T4        T7  \\\n",
      "0  396.614090  179.453893   673.961939   4.199028   3.063464  1.254181   \n",
      "1  716.477570  716.242822  2560.734611  11.031872   7.909028  3.359525   \n",
      "2  249.787542   36.917722   100.063143   1.169048   0.888382  0.342685   \n",
      "3  888.418646  731.016700  2277.399087  22.827090  15.809505  6.899293   \n",
      "4  175.355852  180.392630   422.334951   2.194573   1.756323  0.693367   \n",
      "\n",
      "          T8        T9        T10       T11         T5  \n",
      "0  22.254757  0.007995   6.954702  0.000000  34.238893  \n",
      "1  52.670365  0.087936  10.430421  0.036200  22.110378  \n",
      "2   5.868663  0.027224   2.942095  0.000259   6.221572  \n",
      "3  81.432865  0.000000  34.419754  0.000000  16.030205  \n",
      "4  15.758243  0.000000   4.469411  0.005231  11.052639  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         L1        L2        L3        L4        L5        L6        L7  \\\n",
       "0  0.005477  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.016640  0.004072  0.069643  0.123688  0.000000  0.007365  0.007276   \n",
       "2  0.067981  0.000000  0.013596  0.053496  0.000000  0.000000  0.000000   \n",
       "3  0.546691  0.025162  0.115282  0.449221  1.041129  0.000000  0.007867   \n",
       "4  0.117176  0.059917  0.000000  0.067867  0.080017  0.059768  0.037533   \n",
       "\n",
       "         L8        L9       L10  ...        C2        H2         H3        H4  \\\n",
       "0  0.000000  0.000000  0.008500  ...  3.045662  8.579017  29.018830  3.646602   \n",
       "1  0.000000  0.000000  0.000000  ...  0.990749  8.447919  27.682428  2.325901   \n",
       "2  0.008777  0.000000  0.023665  ...  0.979768  9.506858  24.936928  4.654782   \n",
       "3  0.048825  0.000000  0.000000  ...  6.013421  7.254344  26.876190  2.464772   \n",
       "4  0.077548  0.044131  0.028936  ...  1.039374  9.123762  32.668775  4.059705   \n",
       "\n",
       "         H5         T5          H9       H10           H11         H12  \n",
       "0  0.531858  34.238893   19.603891  0.055240  46445.299255  276.380196  \n",
       "1  0.189171  22.110378  115.931178  0.061129  29785.452246  290.797341  \n",
       "2  0.756782   6.221572   16.012457  0.000000  19598.888752  272.694758  \n",
       "3  1.155325  16.030205  142.034012  0.000000  10896.155792  287.459756  \n",
       "4  2.213218  11.052639   38.298921  0.024917  29128.025386  271.329192  \n",
       "\n",
       "[5 rows x 56 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>L3</th>\n",
       "      <th>L4</th>\n",
       "      <th>L5</th>\n",
       "      <th>L6</th>\n",
       "      <th>L7</th>\n",
       "      <th>L8</th>\n",
       "      <th>L9</th>\n",
       "      <th>L10</th>\n",
       "      <th>...</th>\n",
       "      <th>C2</th>\n",
       "      <th>H2</th>\n",
       "      <th>H3</th>\n",
       "      <th>H4</th>\n",
       "      <th>H5</th>\n",
       "      <th>T5</th>\n",
       "      <th>H9</th>\n",
       "      <th>H10</th>\n",
       "      <th>H11</th>\n",
       "      <th>H12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005477</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>...</td>\n",
       "      <td>3.045662</td>\n",
       "      <td>8.579017</td>\n",
       "      <td>29.018830</td>\n",
       "      <td>3.646602</td>\n",
       "      <td>0.531858</td>\n",
       "      <td>34.238893</td>\n",
       "      <td>19.603891</td>\n",
       "      <td>0.055240</td>\n",
       "      <td>46445.299255</td>\n",
       "      <td>276.380196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016640</td>\n",
       "      <td>0.004072</td>\n",
       "      <td>0.069643</td>\n",
       "      <td>0.123688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007365</td>\n",
       "      <td>0.007276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.990749</td>\n",
       "      <td>8.447919</td>\n",
       "      <td>27.682428</td>\n",
       "      <td>2.325901</td>\n",
       "      <td>0.189171</td>\n",
       "      <td>22.110378</td>\n",
       "      <td>115.931178</td>\n",
       "      <td>0.061129</td>\n",
       "      <td>29785.452246</td>\n",
       "      <td>290.797341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.067981</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013596</td>\n",
       "      <td>0.053496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008777</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.979768</td>\n",
       "      <td>9.506858</td>\n",
       "      <td>24.936928</td>\n",
       "      <td>4.654782</td>\n",
       "      <td>0.756782</td>\n",
       "      <td>6.221572</td>\n",
       "      <td>16.012457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19598.888752</td>\n",
       "      <td>272.694758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.546691</td>\n",
       "      <td>0.025162</td>\n",
       "      <td>0.115282</td>\n",
       "      <td>0.449221</td>\n",
       "      <td>1.041129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007867</td>\n",
       "      <td>0.048825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.013421</td>\n",
       "      <td>7.254344</td>\n",
       "      <td>26.876190</td>\n",
       "      <td>2.464772</td>\n",
       "      <td>1.155325</td>\n",
       "      <td>16.030205</td>\n",
       "      <td>142.034012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10896.155792</td>\n",
       "      <td>287.459756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.117176</td>\n",
       "      <td>0.059917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067867</td>\n",
       "      <td>0.080017</td>\n",
       "      <td>0.059768</td>\n",
       "      <td>0.037533</td>\n",
       "      <td>0.077548</td>\n",
       "      <td>0.044131</td>\n",
       "      <td>0.028936</td>\n",
       "      <td>...</td>\n",
       "      <td>1.039374</td>\n",
       "      <td>9.123762</td>\n",
       "      <td>32.668775</td>\n",
       "      <td>4.059705</td>\n",
       "      <td>2.213218</td>\n",
       "      <td>11.052639</td>\n",
       "      <td>38.298921</td>\n",
       "      <td>0.024917</td>\n",
       "      <td>29128.025386</td>\n",
       "      <td>271.329192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data profiling",
   "id": "f943cefc1cb3815"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T05:05:42.320327Z",
     "start_time": "2024-12-16T05:03:56.723605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "# Loop through each category and generate profiling reports\n",
    "for category, columns in categories.items():\n",
    "    category_df = data[columns]\n",
    "    profile = ProfileReport(category_df, title=f\"{category} Profiling Report\", explorative=True)\n",
    "    profile.to_file(f\"{category}_profiling_report.html\")\n",
    "\n",
    "print(\"Profiling reports have been generated for all categories.\")"
   ],
   "id": "34efc4cfb45d9b95",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\prediction flood drivers\\Predicting-Flood-Drivers\\venv\\Lib\\site-packages\\ydata_profiling\\utils\\dataframe.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={\"index\": \"df_index\"}, inplace=True)\n",
      "Summarize dataset: 100%|██████████| 165/165 [00:15<00:00, 10.89it/s, Completed]               \n",
      "Generate report structure: 100%|██████████| 1/1 [00:03<00:00,  3.32s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:03<00:00,  3.29s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 35.00it/s]\n",
      "D:\\prediction flood drivers\\Predicting-Flood-Drivers\\venv\\Lib\\site-packages\\ydata_profiling\\utils\\dataframe.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={\"index\": \"df_index\"}, inplace=True)\n",
      "Summarize dataset: 100%|██████████| 141/141 [00:13<00:00, 10.27it/s, Completed]               \n",
      "Generate report structure: 100%|██████████| 1/1 [00:03<00:00,  3.22s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:02<00:00,  2.19s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 39.97it/s]\n",
      "D:\\prediction flood drivers\\Predicting-Flood-Drivers\\venv\\Lib\\site-packages\\ydata_profiling\\utils\\dataframe.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={\"index\": \"df_index\"}, inplace=True)\n",
      "Summarize dataset: 100%|██████████| 165/165 [00:16<00:00,  9.95it/s, Completed]               \n",
      "Generate report structure: 100%|██████████| 1/1 [00:03<00:00,  3.53s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:02<00:00,  2.53s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 31.07it/s]\n",
      "D:\\prediction flood drivers\\Predicting-Flood-Drivers\\venv\\Lib\\site-packages\\ydata_profiling\\utils\\dataframe.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={\"index\": \"df_index\"}, inplace=True)\n",
      "Summarize dataset: 100%|██████████| 81/81 [00:07<00:00, 11.44it/s, Completed]                  \n",
      "Generate report structure: 100%|██████████| 1/1 [00:02<00:00,  2.55s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 45.92it/s]\n",
      "D:\\prediction flood drivers\\Predicting-Flood-Drivers\\venv\\Lib\\site-packages\\ydata_profiling\\utils\\dataframe.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={\"index\": \"df_index\"}, inplace=True)\n",
      "Summarize dataset: 100%|██████████| 141/141 [00:13<00:00, 10.13it/s, Completed]               \n",
      "Generate report structure: 100%|██████████| 1/1 [00:03<00:00,  3.45s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 45.44it/s]\n",
      "D:\\prediction flood drivers\\Predicting-Flood-Drivers\\venv\\Lib\\site-packages\\ydata_profiling\\utils\\dataframe.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={\"index\": \"df_index\"}, inplace=True)\n",
      "Summarize dataset: 100%|██████████| 15/15 [00:00<00:00, 20.95it/s, Completed]                \n",
      "Generate report structure: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
      "Render HTML: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 195.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiling reports have been generated for all categories.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Pair plots\n",
   "id": "ad5dcf8c5f4d7d50"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T05:15:36.063658Z",
     "start_time": "2024-12-16T05:09:56.591468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Loop through each category and save pair plots\n",
    "for category, columns in categories.items():\n",
    "    if len(columns) > 1:  # Ensure there are at least two columns for pair plots\n",
    "        print(f\"Generating and saving pair plot for {category}...\")  # Inform the user\n",
    "        pair_plot = sns.pairplot(data[columns])  # Generate pair plot\n",
    "        pair_plot.fig.suptitle(f\"{category} Pair Plot\", y=1.02)  # Add title to the plot\n",
    "        file_name = f\"{category}_pair_plot.png\"  # Define the file name\n",
    "        pair_plot.savefig(file_name)  # Save the plot as a PNG file\n",
    "        plt.close(pair_plot.fig)  # Close the plot to free memory\n",
    "        print(f\"Saved pair plot for {category} as {file_name}.\")  # Confirm save\n",
    "    else:\n",
    "        print(f\"Skipping {category} as it has less than 2 columns.\")  # Skip if not enough columns\n"
   ],
   "id": "349fbbc446f83b36",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating and saving pair plot for Labels...\n",
      "Saved pair plot for Labels as Labels_pair_plot.png.\n",
      "Generating and saving pair plot for Topography...\n",
      "Saved pair plot for Topography as Topography_pair_plot.png.\n",
      "Generating and saving pair plot for Hydrological...\n",
      "Saved pair plot for Hydrological as Hydrological_pair_plot.png.\n",
      "Generating and saving pair plot for Vegetation...\n",
      "Saved pair plot for Vegetation as Vegetation_pair_plot.png.\n",
      "Generating and saving pair plot for Shape...\n",
      "Saved pair plot for Shape as Shape_pair_plot.png.\n",
      "Generating and saving pair plot for Climate...\n",
      "Saved pair plot for Climate as Climate_pair_plot.png.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Normalizing data \n",
   "id": "39fe868c2eec9cb0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In this script, I am preprocessing a dataset by dynamically scaling its feature columns based on their skewness and then generating pair plots for visualization. The scaling process involves identifying highly skewed features and applying a combination of RobustScaler and MinMaxScaler to normalize their distribution, while less skewed features are scaled using percentile clipping or standard Min-Max scaling. The scaled feature data is merged back with the original dataset, retaining identifier and label columns. Finally, pair plots are generated for each category of features, enabling you to visualize relationships and correlations within each category. The pair plots are saved as separate image files for further analysis. This process ensures the dataset is cleaned, normalized, and ready for exploratory data analysis.",
   "id": "87608dd331e2b54e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T19:20:29.970298Z",
     "start_time": "2024-12-17T19:20:29.852626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "\n",
    "# Function to scale features based on skewness\n",
    "def custom_scaling(df, features_columns):\n",
    "    scaled_features = pd.DataFrame(index=df.index)  # Initialize with the original index\n",
    "\n",
    "    for column in features_columns:\n",
    "        # Drop NA values for skewness calculation and scaler fitting\n",
    "        feature_data = df[column].dropna()\n",
    "\n",
    "        # Calculate skewness\n",
    "        skewness = feature_data.skew()\n",
    "\n",
    "        if skewness > 2 or skewness < -2:\n",
    "            # Step 1: Apply RobustScaler to handle skewness\n",
    "            robust_scaler = RobustScaler()\n",
    "            robust_scaled_column = robust_scaler.fit_transform(feature_data.values.reshape(-1, 1))\n",
    "\n",
    "            # Step 2: Apply MinMaxScaler to scale to range [0, 1]\n",
    "            min_max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "            scaled_column = min_max_scaler.fit_transform(robust_scaled_column)\n",
    "\n",
    "            print(f\"{column}: Using RobustScaler + MinMaxScaler (Skewness: {skewness:.2f})\")\n",
    "\n",
    "        elif 1 < skewness <= 2:\n",
    "            # Define min and max using the 1st and 99th percentiles\n",
    "            lower_bound = feature_data.quantile(0.01)\n",
    "            upper_bound = feature_data.quantile(0.99)\n",
    "            scaled_column = ((df[column].clip(lower=lower_bound, upper=upper_bound) - lower_bound) /\n",
    "                             (upper_bound - lower_bound)).values.reshape(-1, 1)\n",
    "\n",
    "            print(f\"{column}: Using Percentile Clipping (Skewness: {skewness:.2f})\")\n",
    "\n",
    "        else:\n",
    "            # Use Min-Max Scaling for less skewed data\n",
    "            min_max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "            scaled_column = min_max_scaler.fit_transform(feature_data.values.reshape(-1, 1))\n",
    "\n",
    "            print(f\"{column}: Using Min-Max Scaling (Skewness: {skewness:.2f})\")\n",
    "\n",
    "        # Add scaled column to the result dataframe (flatten to convert to a 1D array)\n",
    "        scaled_features[column] = scaled_column.flatten()\n",
    "\n",
    "    return scaled_features\n",
    "\n",
    "# Define feature columns (all columns except labels and IDs)\n",
    "label_columns = [col for col in data.columns if col.startswith('L')]\n",
    "features_columns = [col for col in data.columns if col not in label_columns]\n",
    "\n",
    "# Apply the custom scaling function to the data's feature columns\n",
    "scaled_features_df = custom_scaling(data, features_columns)\n",
    "\n",
    "# Merge scaled features back with the original data (if needed)\n",
    "data_scaled = pd.concat([data[label_columns], scaled_features_df], axis=1)\n",
    "\n",
    "scaled_data_file = \"scaled_flood_drivers_dataset.csv\"\n",
    "data_scaled.to_csv(scaled_data_file, index=False)\n",
    "\n",
    "data_scaled.head()\n",
    "\n"
   ],
   "id": "59b8b02572b611f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S11: Using RobustScaler + MinMaxScaler (Skewness: 8.26)\n",
      "S8: Using RobustScaler + MinMaxScaler (Skewness: -4.97)\n",
      "T1: Using Percentile Clipping (Skewness: 1.34)\n",
      "T2: Using Percentile Clipping (Skewness: 1.18)\n",
      "T3: Using Percentile Clipping (Skewness: 1.82)\n",
      "T6: Using Percentile Clipping (Skewness: 1.91)\n",
      "S9: Using Percentile Clipping (Skewness: 1.78)\n",
      "S10: Using Percentile Clipping (Skewness: 1.52)\n",
      "T4: Using Percentile Clipping (Skewness: 1.75)\n",
      "H1: Using Min-Max Scaling (Skewness: 0.07)\n",
      "T7: Using Percentile Clipping (Skewness: 1.92)\n",
      "T8: Using Percentile Clipping (Skewness: 1.84)\n",
      "T9: Using Percentile Clipping (Skewness: 1.13)\n",
      "T10: Using RobustScaler + MinMaxScaler (Skewness: 3.07)\n",
      "V1: Using Min-Max Scaling (Skewness: -0.29)\n",
      "V2: Using Percentile Clipping (Skewness: 1.28)\n",
      "V3: Using RobustScaler + MinMaxScaler (Skewness: 2.96)\n",
      "V4: Using RobustScaler + MinMaxScaler (Skewness: 2.82)\n",
      "V5: Using RobustScaler + MinMaxScaler (Skewness: 3.52)\n",
      "V6: Using RobustScaler + MinMaxScaler (Skewness: 7.17)\n",
      "V7: Using Percentile Clipping (Skewness: 1.14)\n",
      "V8: Using RobustScaler + MinMaxScaler (Skewness: 6.50)\n",
      "H6: Using Percentile Clipping (Skewness: 1.07)\n",
      "S2: Using Percentile Clipping (Skewness: 1.53)\n",
      "S1: Using Min-Max Scaling (Skewness: 0.76)\n",
      "S3: Using Min-Max Scaling (Skewness: -0.47)\n",
      "S4: Using Percentile Clipping (Skewness: 1.02)\n",
      "S5: Using Min-Max Scaling (Skewness: 0.01)\n",
      "S7: Using Min-Max Scaling (Skewness: -0.45)\n",
      "S6: Using Min-Max Scaling (Skewness: 0.16)\n",
      "T11: Using Percentile Clipping (Skewness: 1.30)\n",
      "H7: Using Percentile Clipping (Skewness: 1.86)\n",
      "H8: Using Percentile Clipping (Skewness: 1.81)\n",
      "C1: Using Min-Max Scaling (Skewness: 0.95)\n",
      "C2: Using RobustScaler + MinMaxScaler (Skewness: 3.01)\n",
      "H2: Using Min-Max Scaling (Skewness: -0.24)\n",
      "H3: Using Min-Max Scaling (Skewness: 0.18)\n",
      "H4: Using Min-Max Scaling (Skewness: -0.03)\n",
      "H5: Using RobustScaler + MinMaxScaler (Skewness: 2.47)\n",
      "T5: Using RobustScaler + MinMaxScaler (Skewness: 2.18)\n",
      "H9: Using RobustScaler + MinMaxScaler (Skewness: 2.58)\n",
      "H10: Using Percentile Clipping (Skewness: 1.19)\n",
      "H11: Using Percentile Clipping (Skewness: 1.12)\n",
      "H12: Using RobustScaler + MinMaxScaler (Skewness: 3.81)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         L1        L2        L3        L4        L5        L6        L7  \\\n",
       "0  0.005477  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.016640  0.004072  0.069643  0.123688  0.000000  0.007365  0.007276   \n",
       "2  0.067981  0.000000  0.013596  0.053496  0.000000  0.000000  0.000000   \n",
       "3  0.546691  0.025162  0.115282  0.449221  1.041129  0.000000  0.007867   \n",
       "4  0.117176  0.059917  0.000000  0.067867  0.080017  0.059768  0.037533   \n",
       "\n",
       "         L8        L9       L10  ...        C2        H2        H3        H4  \\\n",
       "0  0.000000  0.000000  0.008500  ...  0.060988  0.547630  0.612131  0.521886   \n",
       "1  0.000000  0.000000  0.000000  ...  0.019839  0.512374  0.526266  0.206557   \n",
       "2  0.008777  0.000000  0.023665  ...  0.019619  0.797151  0.349864  0.762598   \n",
       "3  0.048825  0.000000  0.000000  ...  0.120415  0.191390  0.474464  0.239714   \n",
       "4  0.077548  0.044131  0.028936  ...  0.020813  0.694126  0.846645  0.620518   \n",
       "\n",
       "         H5        T5        H9       H10       H11       H12  \n",
       "0  0.037818  0.298928  0.039498  0.529595  0.685924  0.055321  \n",
       "1  0.005339  0.189567  0.326540  0.586057  0.432310  0.172894  \n",
       "2  0.059135  0.046301  0.028796  0.000000  0.277240  0.025265  \n",
       "3  0.096908  0.134743  0.404323  0.000000  0.144758  0.145675  \n",
       "4  0.197171  0.089861  0.095207  0.238884  0.422302  0.014129  \n",
       "\n",
       "[5 rows x 56 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>L3</th>\n",
       "      <th>L4</th>\n",
       "      <th>L5</th>\n",
       "      <th>L6</th>\n",
       "      <th>L7</th>\n",
       "      <th>L8</th>\n",
       "      <th>L9</th>\n",
       "      <th>L10</th>\n",
       "      <th>...</th>\n",
       "      <th>C2</th>\n",
       "      <th>H2</th>\n",
       "      <th>H3</th>\n",
       "      <th>H4</th>\n",
       "      <th>H5</th>\n",
       "      <th>T5</th>\n",
       "      <th>H9</th>\n",
       "      <th>H10</th>\n",
       "      <th>H11</th>\n",
       "      <th>H12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005477</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060988</td>\n",
       "      <td>0.547630</td>\n",
       "      <td>0.612131</td>\n",
       "      <td>0.521886</td>\n",
       "      <td>0.037818</td>\n",
       "      <td>0.298928</td>\n",
       "      <td>0.039498</td>\n",
       "      <td>0.529595</td>\n",
       "      <td>0.685924</td>\n",
       "      <td>0.055321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016640</td>\n",
       "      <td>0.004072</td>\n",
       "      <td>0.069643</td>\n",
       "      <td>0.123688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007365</td>\n",
       "      <td>0.007276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019839</td>\n",
       "      <td>0.512374</td>\n",
       "      <td>0.526266</td>\n",
       "      <td>0.206557</td>\n",
       "      <td>0.005339</td>\n",
       "      <td>0.189567</td>\n",
       "      <td>0.326540</td>\n",
       "      <td>0.586057</td>\n",
       "      <td>0.432310</td>\n",
       "      <td>0.172894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.067981</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013596</td>\n",
       "      <td>0.053496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008777</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019619</td>\n",
       "      <td>0.797151</td>\n",
       "      <td>0.349864</td>\n",
       "      <td>0.762598</td>\n",
       "      <td>0.059135</td>\n",
       "      <td>0.046301</td>\n",
       "      <td>0.028796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.277240</td>\n",
       "      <td>0.025265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.546691</td>\n",
       "      <td>0.025162</td>\n",
       "      <td>0.115282</td>\n",
       "      <td>0.449221</td>\n",
       "      <td>1.041129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007867</td>\n",
       "      <td>0.048825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120415</td>\n",
       "      <td>0.191390</td>\n",
       "      <td>0.474464</td>\n",
       "      <td>0.239714</td>\n",
       "      <td>0.096908</td>\n",
       "      <td>0.134743</td>\n",
       "      <td>0.404323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144758</td>\n",
       "      <td>0.145675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.117176</td>\n",
       "      <td>0.059917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067867</td>\n",
       "      <td>0.080017</td>\n",
       "      <td>0.059768</td>\n",
       "      <td>0.037533</td>\n",
       "      <td>0.077548</td>\n",
       "      <td>0.044131</td>\n",
       "      <td>0.028936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020813</td>\n",
       "      <td>0.694126</td>\n",
       "      <td>0.846645</td>\n",
       "      <td>0.620518</td>\n",
       "      <td>0.197171</td>\n",
       "      <td>0.089861</td>\n",
       "      <td>0.095207</td>\n",
       "      <td>0.238884</td>\n",
       "      <td>0.422302</td>\n",
       "      <td>0.014129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Scaled Data Profiling",
   "id": "e8f6740f0aef1346"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T05:26:53.516799Z",
     "start_time": "2024-12-16T05:23:24.377024Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating and saving pair plot for Labels...\n",
      "Saved pair plot for Labels as Labels_pair_plot.png.\n",
      "Generating and saving pair plot for Topography...\n",
      "Saved pair plot for Topography as Topography_pair_plot.png.\n",
      "Generating and saving pair plot for Hydrological...\n",
      "Saved pair plot for Hydrological as Hydrological_pair_plot.png.\n",
      "Generating and saving pair plot for Vegetation...\n",
      "Saved pair plot for Vegetation as Vegetation_pair_plot.png.\n",
      "Generating and saving pair plot for Shape...\n",
      "Saved pair plot for Shape as Shape_pair_plot.png.\n",
      "Generating and saving pair plot for Climate...\n",
      "Saved pair plot for Climate as Climate_pair_plot.png.\n"
     ]
    }
   ],
   "execution_count": 16,
   "source": [
    "# Generate and save pair plots for each category\n",
    "for category, columns in categories.items():\n",
    "    if len(columns) > 1:  # Ensure there are at least two columns for pair plots\n",
    "        print(f\"Generating and saving pair plot for {category}...\")  # Inform the user\n",
    "        category_df = data_scaled[columns]  # Use scaled data for pair plots\n",
    "        pair_plot = sns.pairplot(category_df)  # Generate pair plot\n",
    "        pair_plot.fig.suptitle(f\"{category} Pair Plot\", y=1.02)  # Add title to the plot\n",
    "        file_name = f\"{category}_pair_plot.png\"  # Define the file name\n",
    "        pair_plot.savefig(file_name)  # Save the plot as a PNG file\n",
    "        plt.close(pair_plot.fig)  # Close the plot to free memory\n",
    "        print(f\"Saved pair plot for {category} as {file_name}.\")  # Confirm save\n",
    "    else:\n",
    "        print(f\"Skipping {category} as it has less than 2 columns.\")  # Skip if not enough columns\n"
   ],
   "id": "93910e9356551ed6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "d173dbb777c9efb1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "source": "",
   "id": "128e2a7fd13226ea",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
