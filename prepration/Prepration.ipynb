{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T04:58:05.792336Z",
     "start_time": "2024-12-16T04:58:05.481771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from seaborn import xkcd_palette\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import numpy as np"
   ],
   "id": "9ec7a658d3634e25",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T05:01:45.766142Z",
     "start_time": "2024-12-16T05:01:45.720363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('D:\\\\Data analysis\\\\Data-Analysis-2024\\\\Project\\\\Data\\\\renamed_flood_drivers_dataset.csv')\n",
    "\n",
    "# Identify label columns (assuming they are named L1, L2, ..., Ln)\n",
    "label_columns = [col for col in data.columns if col.startswith('L')]\n",
    "\n",
    "# Define categories based on column prefixes\n",
    "categories = {\n",
    "    \"Labels\": label_columns,\n",
    "    \"Topography\": [col for col in data.columns if col.startswith(\"T\")],\n",
    "    \"Hydrological\": [col for col in data.columns if col.startswith(\"H\")],\n",
    "    \"Vegetation\": [col for col in data.columns if col.startswith(\"V\")],\n",
    "    \"Shape\": [col for col in data.columns if col.startswith(\"S\")],\n",
    "    \"Climate\": [col for col in data.columns if col.startswith(\"C\")]\n",
    "}\n",
    "\n",
    "# Create separate dataframes for each category\n",
    "category_dataframes = {category: data[columns] for category, columns in categories.items()}\n",
    "\n",
    "# Print each category and its columns\n",
    "print(\"Categories and their columns:\")\n",
    "for category, columns in categories.items():\n",
    "    print(f\"\\nCategory: {category}\")\n",
    "    print(f\"Columns: {columns}\")\n",
    "\n",
    "# Preview one of the category-specific dataframes (e.g., Topography)\n",
    "print(\"\\nPreview of Topography DataFrame:\")\n",
    "print(category_dataframes[\"Topography\"].head())\n",
    "data.head()"
   ],
   "id": "598a710308236194",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories and their columns:\n",
      "\n",
      "Category: Labels\n",
      "Columns: ['L1', 'L2', 'L3', 'L4', 'L5', 'L6', 'L7', 'L8', 'L9', 'L10', 'L11', 'L12']\n",
      "\n",
      "Category: Topography\n",
      "Columns: ['T1', 'T2', 'T3', 'T6', 'T4', 'T7', 'T8', 'T9', 'T10', 'T11', 'T5']\n",
      "\n",
      "Category: Hydrological\n",
      "Columns: ['H1', 'H6', 'H7', 'H8', 'H2', 'H3', 'H4', 'H5', 'H9', 'H10', 'H11', 'H12']\n",
      "\n",
      "Category: Vegetation\n",
      "Columns: ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8']\n",
      "\n",
      "Category: Shape\n",
      "Columns: ['S11', 'S8', 'S9', 'S10', 'S2', 'S1', 'S3', 'S4', 'S5', 'S7', 'S6']\n",
      "\n",
      "Category: Climate\n",
      "Columns: ['C1', 'C2']\n",
      "\n",
      "Preview of Topography DataFrame:\n",
      "           T1          T2           T3         T6         T4        T7  \\\n",
      "0  943.073454  287.944548   633.105591   3.879041   2.831437  1.188155   \n",
      "1  924.199384  751.763822  1790.568832  23.747618  16.359541  7.192878   \n",
      "2  419.587262  318.989484   691.339966   7.896609   5.696233  2.415654   \n",
      "3  257.698544   42.792996    95.690002   0.783354   0.564890  0.241001   \n",
      "4   68.839492   76.670603   338.386653   2.147734   1.574833  0.656018   \n",
      "\n",
      "          T8        T9        T10       T11         T5  \n",
      "0  16.675446 -0.000536  10.574600  0.002938   3.235646  \n",
      "1  58.065834 -0.003045  15.942787  0.001918  22.936546  \n",
      "2  54.330143 -0.001629  19.288616  0.003261  20.176721  \n",
      "3   3.891251 -0.000025   1.391106  0.001476   2.924428  \n",
      "4  25.510834  0.000382  11.871247  0.003584   2.849114  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    L1   L2   L3   L4   L5   L6   L7   L8   L9  L10  ...    C2        H2  \\\n",
       "0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  66.0  8.694593   \n",
       "1  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...   3.0  7.123628   \n",
       "2  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...   8.0  7.912272   \n",
       "3  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...   6.0  9.814917   \n",
       "4  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  16.0  9.494923   \n",
       "\n",
       "          H3        H4        H5         T5          H9       H10  \\\n",
       "0  28.527079  3.977521  1.077355   3.235646  195.665874  0.000002   \n",
       "1  27.878817  2.825853  0.243328  22.936546   78.066193  0.000002   \n",
       "2  28.811127  3.069299  2.299067  20.176721   34.264238  0.000002   \n",
       "3  29.317530  5.223006  0.365525   2.924428   32.720929  0.000002   \n",
       "4  35.016827  3.461281  0.338012   2.849114  118.769102  0.000002   \n",
       "\n",
       "           H11         H12  \n",
       "0  14591.15909  283.497115  \n",
       "1  12454.68414  289.041674  \n",
       "2  40087.84291  279.169976  \n",
       "3  11218.53321  271.549335  \n",
       "4  48105.42083  289.132413  \n",
       "\n",
       "[5 rows x 56 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>L3</th>\n",
       "      <th>L4</th>\n",
       "      <th>L5</th>\n",
       "      <th>L6</th>\n",
       "      <th>L7</th>\n",
       "      <th>L8</th>\n",
       "      <th>L9</th>\n",
       "      <th>L10</th>\n",
       "      <th>...</th>\n",
       "      <th>C2</th>\n",
       "      <th>H2</th>\n",
       "      <th>H3</th>\n",
       "      <th>H4</th>\n",
       "      <th>H5</th>\n",
       "      <th>T5</th>\n",
       "      <th>H9</th>\n",
       "      <th>H10</th>\n",
       "      <th>H11</th>\n",
       "      <th>H12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>8.694593</td>\n",
       "      <td>28.527079</td>\n",
       "      <td>3.977521</td>\n",
       "      <td>1.077355</td>\n",
       "      <td>3.235646</td>\n",
       "      <td>195.665874</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>14591.15909</td>\n",
       "      <td>283.497115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.123628</td>\n",
       "      <td>27.878817</td>\n",
       "      <td>2.825853</td>\n",
       "      <td>0.243328</td>\n",
       "      <td>22.936546</td>\n",
       "      <td>78.066193</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>12454.68414</td>\n",
       "      <td>289.041674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.912272</td>\n",
       "      <td>28.811127</td>\n",
       "      <td>3.069299</td>\n",
       "      <td>2.299067</td>\n",
       "      <td>20.176721</td>\n",
       "      <td>34.264238</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>40087.84291</td>\n",
       "      <td>279.169976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.814917</td>\n",
       "      <td>29.317530</td>\n",
       "      <td>5.223006</td>\n",
       "      <td>0.365525</td>\n",
       "      <td>2.924428</td>\n",
       "      <td>32.720929</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>11218.53321</td>\n",
       "      <td>271.549335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.494923</td>\n",
       "      <td>35.016827</td>\n",
       "      <td>3.461281</td>\n",
       "      <td>0.338012</td>\n",
       "      <td>2.849114</td>\n",
       "      <td>118.769102</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>48105.42083</td>\n",
       "      <td>289.132413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data profiling",
   "id": "f943cefc1cb3815"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T05:05:42.320327Z",
     "start_time": "2024-12-16T05:03:56.723605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "# Loop through each category and generate profiling reports\n",
    "for category, columns in categories.items():\n",
    "    category_df = data[columns]\n",
    "    profile = ProfileReport(category_df, title=f\"{category} Profiling Report\", explorative=True)\n",
    "    profile.to_file(f\"{category}_profiling_report.html\")\n",
    "\n",
    "print(\"Profiling reports have been generated for all categories.\")"
   ],
   "id": "34efc4cfb45d9b95",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\prediction flood drivers\\Predicting-Flood-Drivers\\venv\\Lib\\site-packages\\ydata_profiling\\utils\\dataframe.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={\"index\": \"df_index\"}, inplace=True)\n",
      "Summarize dataset: 100%|██████████| 165/165 [00:15<00:00, 10.89it/s, Completed]               \n",
      "Generate report structure: 100%|██████████| 1/1 [00:03<00:00,  3.32s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:03<00:00,  3.29s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 35.00it/s]\n",
      "D:\\prediction flood drivers\\Predicting-Flood-Drivers\\venv\\Lib\\site-packages\\ydata_profiling\\utils\\dataframe.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={\"index\": \"df_index\"}, inplace=True)\n",
      "Summarize dataset: 100%|██████████| 141/141 [00:13<00:00, 10.27it/s, Completed]               \n",
      "Generate report structure: 100%|██████████| 1/1 [00:03<00:00,  3.22s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:02<00:00,  2.19s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 39.97it/s]\n",
      "D:\\prediction flood drivers\\Predicting-Flood-Drivers\\venv\\Lib\\site-packages\\ydata_profiling\\utils\\dataframe.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={\"index\": \"df_index\"}, inplace=True)\n",
      "Summarize dataset: 100%|██████████| 165/165 [00:16<00:00,  9.95it/s, Completed]               \n",
      "Generate report structure: 100%|██████████| 1/1 [00:03<00:00,  3.53s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:02<00:00,  2.53s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 31.07it/s]\n",
      "D:\\prediction flood drivers\\Predicting-Flood-Drivers\\venv\\Lib\\site-packages\\ydata_profiling\\utils\\dataframe.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={\"index\": \"df_index\"}, inplace=True)\n",
      "Summarize dataset: 100%|██████████| 81/81 [00:07<00:00, 11.44it/s, Completed]                  \n",
      "Generate report structure: 100%|██████████| 1/1 [00:02<00:00,  2.55s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 45.92it/s]\n",
      "D:\\prediction flood drivers\\Predicting-Flood-Drivers\\venv\\Lib\\site-packages\\ydata_profiling\\utils\\dataframe.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={\"index\": \"df_index\"}, inplace=True)\n",
      "Summarize dataset: 100%|██████████| 141/141 [00:13<00:00, 10.13it/s, Completed]               \n",
      "Generate report structure: 100%|██████████| 1/1 [00:03<00:00,  3.45s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 45.44it/s]\n",
      "D:\\prediction flood drivers\\Predicting-Flood-Drivers\\venv\\Lib\\site-packages\\ydata_profiling\\utils\\dataframe.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={\"index\": \"df_index\"}, inplace=True)\n",
      "Summarize dataset: 100%|██████████| 15/15 [00:00<00:00, 20.95it/s, Completed]                \n",
      "Generate report structure: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
      "Render HTML: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 195.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiling reports have been generated for all categories.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Pair plots\n",
   "id": "ad5dcf8c5f4d7d50"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T05:15:36.063658Z",
     "start_time": "2024-12-16T05:09:56.591468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Loop through each category and save pair plots\n",
    "for category, columns in categories.items():\n",
    "    if len(columns) > 1:  # Ensure there are at least two columns for pair plots\n",
    "        print(f\"Generating and saving pair plot for {category}...\")  # Inform the user\n",
    "        pair_plot = sns.pairplot(data[columns])  # Generate pair plot\n",
    "        pair_plot.fig.suptitle(f\"{category} Pair Plot\", y=1.02)  # Add title to the plot\n",
    "        file_name = f\"{category}_pair_plot.png\"  # Define the file name\n",
    "        pair_plot.savefig(file_name)  # Save the plot as a PNG file\n",
    "        plt.close(pair_plot.fig)  # Close the plot to free memory\n",
    "        print(f\"Saved pair plot for {category} as {file_name}.\")  # Confirm save\n",
    "    else:\n",
    "        print(f\"Skipping {category} as it has less than 2 columns.\")  # Skip if not enough columns\n"
   ],
   "id": "349fbbc446f83b36",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating and saving pair plot for Labels...\n",
      "Saved pair plot for Labels as Labels_pair_plot.png.\n",
      "Generating and saving pair plot for Topography...\n",
      "Saved pair plot for Topography as Topography_pair_plot.png.\n",
      "Generating and saving pair plot for Hydrological...\n",
      "Saved pair plot for Hydrological as Hydrological_pair_plot.png.\n",
      "Generating and saving pair plot for Vegetation...\n",
      "Saved pair plot for Vegetation as Vegetation_pair_plot.png.\n",
      "Generating and saving pair plot for Shape...\n",
      "Saved pair plot for Shape as Shape_pair_plot.png.\n",
      "Generating and saving pair plot for Climate...\n",
      "Saved pair plot for Climate as Climate_pair_plot.png.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Normalizing data \n",
   "id": "39fe868c2eec9cb0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In this script, I am preprocessing a dataset by dynamically scaling its feature columns based on their skewness and then generating pair plots for visualization. The scaling process involves identifying highly skewed features and applying a combination of RobustScaler and MinMaxScaler to normalize their distribution, while less skewed features are scaled using percentile clipping or standard Min-Max scaling. The scaled feature data is merged back with the original dataset, retaining identifier and label columns. Finally, pair plots are generated for each category of features, enabling you to visualize relationships and correlations within each category. The pair plots are saved as separate image files for further analysis. This process ensures the dataset is cleaned, normalized, and ready for exploratory data analysis.",
   "id": "87608dd331e2b54e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T05:21:41.601974Z",
     "start_time": "2024-12-16T05:21:41.222531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "\n",
    "# Function to scale features based on skewness\n",
    "def custom_scaling(df, features_columns):\n",
    "    scaled_features = pd.DataFrame(index=df.index)  # Initialize with the original index\n",
    "\n",
    "    for column in features_columns:\n",
    "        # Drop NA values for skewness calculation and scaler fitting\n",
    "        feature_data = df[column].dropna()\n",
    "\n",
    "        # Calculate skewness\n",
    "        skewness = feature_data.skew()\n",
    "\n",
    "        if skewness > 2 or skewness < -2:\n",
    "            # Step 1: Apply RobustScaler to handle skewness\n",
    "            robust_scaler = RobustScaler()\n",
    "            robust_scaled_column = robust_scaler.fit_transform(feature_data.values.reshape(-1, 1))\n",
    "\n",
    "            # Step 2: Apply MinMaxScaler to scale to range [0, 1]\n",
    "            min_max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "            scaled_column = min_max_scaler.fit_transform(robust_scaled_column)\n",
    "\n",
    "            print(f\"{column}: Using RobustScaler + MinMaxScaler (Skewness: {skewness:.2f})\")\n",
    "\n",
    "        elif 1 < skewness <= 2:\n",
    "            # Define min and max using the 1st and 99th percentiles\n",
    "            lower_bound = feature_data.quantile(0.01)\n",
    "            upper_bound = feature_data.quantile(0.99)\n",
    "            scaled_column = ((df[column].clip(lower=lower_bound, upper=upper_bound) - lower_bound) /\n",
    "                             (upper_bound - lower_bound)).values.reshape(-1, 1)\n",
    "\n",
    "            print(f\"{column}: Using Percentile Clipping (Skewness: {skewness:.2f})\")\n",
    "\n",
    "        else:\n",
    "            # Use Min-Max Scaling for less skewed data\n",
    "            min_max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "            scaled_column = min_max_scaler.fit_transform(feature_data.values.reshape(-1, 1))\n",
    "\n",
    "            print(f\"{column}: Using Min-Max Scaling (Skewness: {skewness:.2f})\")\n",
    "\n",
    "        # Add scaled column to the result dataframe (flatten to convert to a 1D array)\n",
    "        scaled_features[column] = scaled_column.flatten()\n",
    "\n",
    "    return scaled_features\n",
    "\n",
    "# Define feature columns (all columns except labels and IDs)\n",
    "label_columns = [col for col in data.columns if col.startswith('L')]\n",
    "id_columns = ['tile_id', 'tile_name_', 'WSID']\n",
    "features_columns = [col for col in data.columns if col not in label_columns + id_columns]\n",
    "\n",
    "# Apply the custom scaling function to the data's feature columns\n",
    "scaled_features_df = custom_scaling(data, features_columns)\n",
    "\n",
    "# Merge scaled features back with the original data (if needed)\n",
    "data_scaled = pd.concat([data[label_columns], scaled_features_df], axis=1)\n",
    "\n",
    "scaled_data_file = \"scaled_flood_drivers_dataset.csv\"\n",
    "data_scaled.to_csv(scaled_data_file, index=False)\n",
    "\n",
    "data_scaled.head()\n",
    "\n"
   ],
   "id": "59b8b02572b611f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S11: Using RobustScaler + MinMaxScaler (Skewness: 7.80)\n",
      "S8: Using RobustScaler + MinMaxScaler (Skewness: -6.47)\n",
      "T1: Using Percentile Clipping (Skewness: 1.28)\n",
      "T2: Using Percentile Clipping (Skewness: 1.61)\n",
      "T3: Using Percentile Clipping (Skewness: 1.79)\n",
      "T6: Using Percentile Clipping (Skewness: 1.88)\n",
      "S9: Using RobustScaler + MinMaxScaler (Skewness: -13.18)\n",
      "S10: Using RobustScaler + MinMaxScaler (Skewness: -2.28)\n",
      "T4: Using Percentile Clipping (Skewness: 1.76)\n",
      "H1: Using Min-Max Scaling (Skewness: 0.41)\n",
      "T7: Using Percentile Clipping (Skewness: 1.88)\n",
      "T8: Using RobustScaler + MinMaxScaler (Skewness: 2.60)\n",
      "T9: Using RobustScaler + MinMaxScaler (Skewness: 2.52)\n",
      "T10: Using RobustScaler + MinMaxScaler (Skewness: 7.81)\n",
      "V1: Using Min-Max Scaling (Skewness: -0.17)\n",
      "V2: Using Percentile Clipping (Skewness: 1.14)\n",
      "V3: Using RobustScaler + MinMaxScaler (Skewness: 3.07)\n",
      "V4: Using RobustScaler + MinMaxScaler (Skewness: 2.54)\n",
      "V5: Using RobustScaler + MinMaxScaler (Skewness: 3.08)\n",
      "V6: Using RobustScaler + MinMaxScaler (Skewness: 8.06)\n",
      "V7: Using RobustScaler + MinMaxScaler (Skewness: 2.29)\n",
      "V8: Using RobustScaler + MinMaxScaler (Skewness: 8.13)\n",
      "H6: Using Percentile Clipping (Skewness: 1.42)\n",
      "S2: Using RobustScaler + MinMaxScaler (Skewness: 16.43)\n",
      "S1: Using Min-Max Scaling (Skewness: 0.74)\n",
      "S3: Using Min-Max Scaling (Skewness: -0.28)\n",
      "S4: Using Percentile Clipping (Skewness: 1.17)\n",
      "S5: Using Min-Max Scaling (Skewness: -0.01)\n",
      "S7: Using Min-Max Scaling (Skewness: -0.17)\n",
      "S6: Using Min-Max Scaling (Skewness: 0.80)\n",
      "T11: Using RobustScaler + MinMaxScaler (Skewness: 2.18)\n",
      "H7: Using Percentile Clipping (Skewness: 1.67)\n",
      "H8: Using Percentile Clipping (Skewness: 1.67)\n",
      "C1: Using Percentile Clipping (Skewness: 1.49)\n",
      "C2: Using RobustScaler + MinMaxScaler (Skewness: 7.70)\n",
      "H2: Using Percentile Clipping (Skewness: 1.96)\n",
      "H3: Using Min-Max Scaling (Skewness: 0.43)\n",
      "H4: Using Percentile Clipping (Skewness: 1.04)\n",
      "H5: Using RobustScaler + MinMaxScaler (Skewness: 3.64)\n",
      "T5: Using RobustScaler + MinMaxScaler (Skewness: 2.26)\n",
      "H9: Using RobustScaler + MinMaxScaler (Skewness: 2.67)\n",
      "H10: Using Min-Max Scaling (Skewness: 0.00)\n",
      "H11: Using Percentile Clipping (Skewness: 1.45)\n",
      "H12: Using RobustScaler + MinMaxScaler (Skewness: 5.98)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    L1   L2   L3   L4   L5   L6   L7   L8   L9  L10  ...        C2        H2  \\\n",
       "0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.323529  0.512363   \n",
       "1  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.014706  0.120433   \n",
       "2  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.039216  0.317187   \n",
       "3  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.029412  0.791865   \n",
       "4  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.078431  0.712032   \n",
       "\n",
       "         H3        H4        H5        T5        H9       H10       H11  \\\n",
       "0  0.411727  0.645739  0.043717  0.026230  0.499246  0.860465  0.165485   \n",
       "1  0.382271  0.313518  0.005087  0.187186  0.198574  0.825581  0.138156   \n",
       "2  0.424634  0.383745  0.100303  0.164638  0.086584  0.895349  0.491625   \n",
       "3  0.447644  1.000000  0.010747  0.023688  0.082638  0.953488  0.122344   \n",
       "4  0.706609  0.496820  0.009473  0.023073  0.302641  0.825581  0.594182   \n",
       "\n",
       "        H12  \n",
       "0  0.080574  \n",
       "1  0.105436  \n",
       "2  0.061172  \n",
       "3  0.027002  \n",
       "4  0.105843  \n",
       "\n",
       "[5 rows x 56 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>L3</th>\n",
       "      <th>L4</th>\n",
       "      <th>L5</th>\n",
       "      <th>L6</th>\n",
       "      <th>L7</th>\n",
       "      <th>L8</th>\n",
       "      <th>L9</th>\n",
       "      <th>L10</th>\n",
       "      <th>...</th>\n",
       "      <th>C2</th>\n",
       "      <th>H2</th>\n",
       "      <th>H3</th>\n",
       "      <th>H4</th>\n",
       "      <th>H5</th>\n",
       "      <th>T5</th>\n",
       "      <th>H9</th>\n",
       "      <th>H10</th>\n",
       "      <th>H11</th>\n",
       "      <th>H12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>0.512363</td>\n",
       "      <td>0.411727</td>\n",
       "      <td>0.645739</td>\n",
       "      <td>0.043717</td>\n",
       "      <td>0.026230</td>\n",
       "      <td>0.499246</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.165485</td>\n",
       "      <td>0.080574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.120433</td>\n",
       "      <td>0.382271</td>\n",
       "      <td>0.313518</td>\n",
       "      <td>0.005087</td>\n",
       "      <td>0.187186</td>\n",
       "      <td>0.198574</td>\n",
       "      <td>0.825581</td>\n",
       "      <td>0.138156</td>\n",
       "      <td>0.105436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.317187</td>\n",
       "      <td>0.424634</td>\n",
       "      <td>0.383745</td>\n",
       "      <td>0.100303</td>\n",
       "      <td>0.164638</td>\n",
       "      <td>0.086584</td>\n",
       "      <td>0.895349</td>\n",
       "      <td>0.491625</td>\n",
       "      <td>0.061172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.791865</td>\n",
       "      <td>0.447644</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010747</td>\n",
       "      <td>0.023688</td>\n",
       "      <td>0.082638</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.122344</td>\n",
       "      <td>0.027002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.712032</td>\n",
       "      <td>0.706609</td>\n",
       "      <td>0.496820</td>\n",
       "      <td>0.009473</td>\n",
       "      <td>0.023073</td>\n",
       "      <td>0.302641</td>\n",
       "      <td>0.825581</td>\n",
       "      <td>0.594182</td>\n",
       "      <td>0.105843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Scaled Data Profiling",
   "id": "e8f6740f0aef1346"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T05:26:53.516799Z",
     "start_time": "2024-12-16T05:23:24.377024Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating and saving pair plot for Labels...\n",
      "Saved pair plot for Labels as Labels_pair_plot.png.\n",
      "Generating and saving pair plot for Topography...\n",
      "Saved pair plot for Topography as Topography_pair_plot.png.\n",
      "Generating and saving pair plot for Hydrological...\n",
      "Saved pair plot for Hydrological as Hydrological_pair_plot.png.\n",
      "Generating and saving pair plot for Vegetation...\n",
      "Saved pair plot for Vegetation as Vegetation_pair_plot.png.\n",
      "Generating and saving pair plot for Shape...\n",
      "Saved pair plot for Shape as Shape_pair_plot.png.\n",
      "Generating and saving pair plot for Climate...\n",
      "Saved pair plot for Climate as Climate_pair_plot.png.\n"
     ]
    }
   ],
   "execution_count": 16,
   "source": [
    "# Generate and save pair plots for each category\n",
    "for category, columns in categories.items():\n",
    "    if len(columns) > 1:  # Ensure there are at least two columns for pair plots\n",
    "        print(f\"Generating and saving pair plot for {category}...\")  # Inform the user\n",
    "        category_df = data_scaled[columns]  # Use scaled data for pair plots\n",
    "        pair_plot = sns.pairplot(category_df)  # Generate pair plot\n",
    "        pair_plot.fig.suptitle(f\"{category} Pair Plot\", y=1.02)  # Add title to the plot\n",
    "        file_name = f\"{category}_pair_plot.png\"  # Define the file name\n",
    "        pair_plot.savefig(file_name)  # Save the plot as a PNG file\n",
    "        plt.close(pair_plot.fig)  # Close the plot to free memory\n",
    "        print(f\"Saved pair plot for {category} as {file_name}.\")  # Confirm save\n",
    "    else:\n",
    "        print(f\"Skipping {category} as it has less than 2 columns.\")  # Skip if not enough columns\n"
   ],
   "id": "93910e9356551ed6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "d173dbb777c9efb1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "source": "",
   "id": "128e2a7fd13226ea",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
